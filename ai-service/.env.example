# AI Service Environment Variables

# HuggingFace API Token (optional for prototype, required for HuggingFace Inference API)
# Get from: https://huggingface.co/settings/tokens
HF_API_TOKEN=

# Optional: HuggingFace Inference API base URL (if using hosted inference)
# e.g. https://api-inference.huggingface.co
HF_INFERENCE_API_URL=

# AI Service Host/Port (for container)
AI_SERVICE_HOST=0.0.0.0
AI_SERVICE_PORT=8000

# Model cache directory (speeds up model loading; mounted as volume in docker-compose)
MODEL_CACHE_DIR=./models

# Logging
LOG_LEVEL=INFO

# Optional service-level API key (if you want the PHP backend to authenticate to this service)
AI_SERVICE_API_KEY=

# Limit maximum text length accepted by endpoints
MAX_TEXT_LENGTH=10000

# Vector dimension (keep in sync with DB migration)
VECTOR_DIMENSIONS=384
